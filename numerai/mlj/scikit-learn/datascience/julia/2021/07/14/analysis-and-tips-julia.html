<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Numerai Analysis &amp; Tips in Julia! | fp.justin.vc</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Numerai Analysis &amp; Tips in Julia!" />
<meta name="author" content="Justin" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This post is a (near) 1:1 replication of the Python Jupyter notebook analysis &amp; tips for the Numerai data science competition, but written in Julia" />
<meta property="og:description" content="This post is a (near) 1:1 replication of the Python Jupyter notebook analysis &amp; tips for the Numerai data science competition, but written in Julia" />
<link rel="canonical" href="https://fp.justin.vc/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis-and-tips-julia.html" />
<meta property="og:url" content="https://fp.justin.vc/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis-and-tips-julia.html" />
<meta property="og:site_name" content="fp.justin.vc" />
<meta property="og:image" content="https://fp.justin.vc/images/numerai.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-07-14T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://fp.justin.vc/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis-and-tips-julia.html","@type":"BlogPosting","author":{"@type":"Person","name":"Justin"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://fp.justin.vc/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis-and-tips-julia.html"},"image":"https://fp.justin.vc/images/numerai.png","headline":"Numerai Analysis &amp; Tips in Julia!","dateModified":"2021-07-14T00:00:00-05:00","datePublished":"2021-07-14T00:00:00-05:00","description":"This post is a (near) 1:1 replication of the Python Jupyter notebook analysis &amp; tips for the Numerai data science competition, but written in Julia","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://fp.justin.vc/feed.xml" title="fp.justin.vc" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-191548033-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-191548033-2');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">fp.justin.vc</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/_pages/about.html">Justin.vc</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Numerai Analysis &amp; Tips in Julia!</h1><p class="page-description">This post is a (near) 1:1 replication of the Python Jupyter notebook analysis & tips for the Numerai data science competition, but written in Julia</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-07-14T00:00:00-05:00" itemprop="datePublished">
        Jul 14, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      15 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#numerai">numerai</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#MLJ">MLJ</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#scikit-learn">scikit-learn</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#datascience">datascience</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#julia">julia</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="n">DataFrames</span> <span class="c"># Requires &gt; 0.22.0 for rownums function</span>
<span class="k">using</span> <span class="n">CSV</span>
<span class="k">using</span> <span class="n">Statistics</span>
<span class="k">using</span> <span class="n">LinearAlgebra</span>
<span class="k">using</span> <span class="n">Plots</span>
<span class="k">using</span> <span class="n">StatsBase</span>
<span class="k">using</span> <span class="n">Distributions</span>
<span class="k">using</span> <span class="n">MLJ</span>
<span class="k">using</span> <span class="n">MLJLinearModels</span>
<span class="k">using</span> <span class="n">MLJXGBoostInterface</span>
<span class="k">using</span> <span class="n">XGBoost</span>
<span class="k">import</span> <span class="n">MLJBase</span><span class="o">:</span> <span class="n">train_test_pairs</span>

<span class="c"># Using for Logistic + CV options, also as an example of how to use Sklearn within Julia</span>
<span class="k">using</span> <span class="n">ScikitLearn</span>

<span class="nd">@sk_import</span> <span class="n">linear_model</span><span class="o">:</span> <span class="x">(</span><span class="n">LogisticRegression</span><span class="x">,</span> <span class="n">LinearRegression</span><span class="x">)</span>
<span class="nd">@sk_import</span> <span class="n">model_selection</span><span class="o">:</span> <span class="x">(</span><span class="n">TimeSeriesSplit</span><span class="x">,</span> <span class="n">KFold</span><span class="x">,</span> <span class="n">GroupKFold</span><span class="x">,</span> <span class="n">cross_val_score</span><span class="x">)</span>
<span class="nd">@sk_import</span> <span class="n">metrics</span><span class="o">:</span> <span class="n">make_scorer</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>┌ Warning: Module model_selection has been ported to Julia - try `import ScikitLearn: CrossValidation` instead
└ @ ScikitLearn.Skcore C:\Users\Justin\.julia\packages\ScikitLearn\ssekP\src\Skcore.jl:179





PyObject &lt;function make_scorer at 0x000000008F07CA60&gt;
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">CSV</span><span class="o">.</span><span class="n">File</span><span class="x">(</span><span class="s">"numerai_training_data.csv"</span><span class="x">)</span> <span class="o">|&gt;</span> <span class="n">DataFrame</span>

<span class="n">first</span><span class="x">(</span><span class="n">df</span><span class="x">,</span><span class="mi">5</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>5 rows × 314 columns (omitted printing of 309 columns)</p><table class="data-frame"><thead><tr><th></th><th>id</th><th>era</th><th>data_type</th><th>feature_intelligence1</th><th>feature_intelligence2</th></tr><tr><th></th><th title="String">String</th><th title="String">String</th><th title="String">String</th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>n000315175b67977</td><td>era1</td><td>train</td><td>0.0</td><td>0.5</td></tr><tr><th>2</th><td>n0014af834a96cdd</td><td>era1</td><td>train</td><td>0.0</td><td>0.0</td></tr><tr><th>3</th><td>n001c93979ac41d4</td><td>era1</td><td>train</td><td>0.25</td><td>0.5</td></tr><tr><th>4</th><td>n0034e4143f22a13</td><td>era1</td><td>train</td><td>1.0</td><td>0.0</td></tr><tr><th>5</th><td>n00679d1a636062f</td><td>era1</td><td>train</td><td>0.25</td><td>0.25</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># There are 501808 rows grouped into eras, and a single target (target)</span>

<span class="n">size</span><span class="x">(</span><span class="n">df</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(501808, 314)
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="n">select</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">r</span><span class="s">"feature"</span><span class="x">)</span> <span class="o">|&gt;</span> <span class="n">names</span>
<span class="n">df</span><span class="o">.</span><span class="n">erano</span> <span class="o">=</span> <span class="n">parse</span><span class="o">.</span><span class="x">(</span><span class="kt">Int64</span><span class="x">,</span> <span class="n">replace</span><span class="o">.</span><span class="x">(</span><span class="n">df</span><span class="o">.</span><span class="n">era</span><span class="x">,</span> <span class="s">"era"</span> <span class="o">=&gt;</span> <span class="s">""</span><span class="x">))</span>
<span class="n">eras</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">erano</span>
<span class="n">target</span> <span class="o">=</span> <span class="s">"target"</span>
<span class="n">length</span><span class="x">(</span><span class="n">features</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>310
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The features are grouped together into 6 types</span>
<span class="n">feature_groups</span> <span class="o">=</span>
    <span class="kt">Dict</span><span class="x">(</span><span class="n">g</span> <span class="o">=&gt;</span> <span class="x">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="k">in</span> <span class="n">features</span> <span class="k">if</span> <span class="n">startswith</span><span class="x">(</span><span class="n">c</span><span class="x">,</span> <span class="s">"feature_</span><span class="si">$</span><span class="s">g"</span><span class="x">)]</span> 
        <span class="k">for</span> <span class="n">g</span> <span class="k">in</span> <span class="x">[</span><span class="s">"intelligence"</span><span class="x">,</span> <span class="s">"wisdom"</span><span class="x">,</span> <span class="s">"charisma"</span><span class="x">,</span> <span class="s">"dexterity"</span><span class="x">,</span> <span class="s">"strength"</span><span class="x">,</span> <span class="s">"constitution"</span><span class="x">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dict{String, Vector{String}} with 6 entries:
  "charisma"     =&gt; ["feature_charisma1", "feature_charisma2", "feature_charism…
  "constitution" =&gt; ["feature_constitution1", "feature_constitution2", "feature…
  "dexterity"    =&gt; ["feature_dexterity1", "feature_dexterity2", "feature_dexte…
  "wisdom"       =&gt; ["feature_wisdom1", "feature_wisdom2", "feature_wisdom3", "…
  "strength"     =&gt; ["feature_strength1", "feature_strength2", "feature_strengt…
  "intelligence" =&gt; ["feature_intelligence1", "feature_intelligence2", "feature…
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The models should be scored based on the rank-correlation (spearman) with the target</span>
<span class="c"># There's probably (definitely) a better way to write this - [ordinalrank would solve the ranking]</span>

<span class="k">function</span><span class="nf"> numerai_score</span><span class="x">(</span><span class="n">y_true</span><span class="x">,</span> <span class="n">y_pred</span><span class="x">,</span> <span class="n">df</span><span class="x">)</span>
        <span class="n">rank_pred</span> <span class="o">=</span> <span class="n">sort</span><span class="x">(</span><span class="n">combine</span><span class="x">(</span><span class="n">groupby</span><span class="x">(</span><span class="n">DataFrame</span><span class="x">(</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span>
                                <span class="x">,</span> <span class="n">eras</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">erano</span>
                                <span class="x">,</span> <span class="n">rnum</span> <span class="o">=</span> <span class="n">rownumber</span><span class="o">.</span><span class="x">(</span><span class="n">eachrow</span><span class="x">(</span><span class="n">df</span><span class="x">)))</span>
                        <span class="x">,</span> <span class="o">:</span><span class="n">eras</span><span class="x">)</span>
                <span class="x">,</span> <span class="n">sdf</span> <span class="o">-&gt;</span> <span class="n">sort</span><span class="x">(</span><span class="n">sdf</span><span class="x">,</span> <span class="o">:</span><span class="n">y_pred</span><span class="x">)</span>
                <span class="x">,</span> <span class="o">:</span><span class="n">eras</span> <span class="o">=&gt;</span> <span class="n">eachindex</span> <span class="o">=&gt;</span> <span class="o">:</span><span class="n">rank</span>
                <span class="x">,</span> <span class="n">nrow</span> <span class="o">=&gt;</span> <span class="o">:</span><span class="n">n</span><span class="x">)</span>
            <span class="x">,</span> <span class="o">:</span><span class="n">rnum</span><span class="x">)</span>

        <span class="n">rank_pred</span> <span class="o">=</span> <span class="n">rank_pred</span><span class="o">.</span><span class="n">rank</span> <span class="o">./</span> <span class="n">rank_pred</span><span class="o">.</span><span class="n">n</span>
    
        <span class="n">cor</span><span class="x">(</span><span class="n">y_true</span><span class="x">,</span> <span class="n">rank_pred</span><span class="x">)</span>
    <span class="k">end</span>

<span class="c"># It can also be convenient while working to evaluate based on the regular (pearson) correlation</span>
<span class="c"># R2 Score to replicate the Python library outputs</span>

<span class="k">function</span><span class="nf"> r2_score</span><span class="x">(</span><span class="n">y_true</span><span class="x">,</span> <span class="n">y_pred</span><span class="x">)</span>
    <span class="nd">@assert</span> <span class="n">length</span><span class="x">(</span><span class="n">y_true</span><span class="x">)</span> <span class="o">==</span> <span class="n">length</span><span class="x">(</span><span class="n">y_pred</span><span class="x">)</span>
    <span class="n">ss_res</span> <span class="o">=</span> <span class="n">sum</span><span class="x">((</span><span class="n">y_true</span> <span class="o">.-</span> <span class="n">y_pred</span><span class="x">)</span><span class="o">.^</span><span class="mi">2</span><span class="x">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">sum</span><span class="x">(</span><span class="n">y_true</span><span class="x">)</span> <span class="o">/</span> <span class="n">length</span><span class="x">(</span><span class="n">y_true</span><span class="x">)</span>
    <span class="n">ss_total</span> <span class="o">=</span> <span class="n">sum</span><span class="x">((</span><span class="n">y_true</span> <span class="o">.-</span> <span class="n">mean</span><span class="x">)</span><span class="o">.^</span><span class="mi">2</span><span class="x">)</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">ss_res</span><span class="o">/</span><span class="x">(</span><span class="n">ss_total</span> <span class="o">+</span> <span class="n">eps</span><span class="x">(</span><span class="n">eltype</span><span class="x">(</span><span class="n">y_pred</span><span class="x">)))</span>
<span class="k">end</span>

<span class="c"># cor() returns a matrix with no need for manipulation, so no need to replicate that here</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>r2_score (generic function with 1 method)
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># There are 120 eras numbered from 1 to 120</span>

<span class="n">describe</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="o">:</span><span class="n">all</span><span class="x">,</span> <span class="n">cols</span><span class="o">=:</span><span class="n">erano</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>1 rows × 13 columns (omitted printing of 3 columns)</p><table class="data-frame"><thead><tr><th></th><th>variable</th><th>mean</th><th>std</th><th>min</th><th>q25</th><th>median</th><th>q75</th><th>max</th><th>nunique</th><th>nmissing</th></tr><tr><th></th><th title="Symbol">Symbol</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Int64">Int64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Int64">Int64</th><th title="Nothing">Nothing</th><th title="Int64">Int64</th></tr></thead><tbody><tr><th>1</th><td>erano</td><td>64.002</td><td>33.3329</td><td>1</td><td>37.0</td><td>64.0</td><td>93.0</td><td>120</td><td></td><td>0</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The earlier eras are smaller, but generally each era is 4000-5000 rows</span>

<span class="n">group_df</span> <span class="o">=</span> <span class="n">combine</span><span class="x">(</span><span class="n">groupby</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="o">:</span><span class="n">erano</span><span class="x">),</span> <span class="n">nrow</span> <span class="o">=&gt;</span> <span class="o">:</span><span class="n">count</span><span class="x">)</span>
<span class="n">plot</span><span class="x">(</span><span class="n">group_df</span><span class="o">.</span><span class="n">erano</span><span class="x">,</span> <span class="n">group_df</span><span class="o">.</span><span class="n">count</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="images/analysis_and_tips_julia_7_0.svg" alt="svg" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARNING: CPU random generator seem to be failing, disabling hardware random number generation
WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The target is discrete and takes on 5 different values</span>

<span class="n">combine</span><span class="x">(</span><span class="n">groupby</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="o">:</span><span class="n">target</span><span class="x">),</span> <span class="n">nrow</span> <span class="o">=&gt;</span> <span class="o">:</span><span class="n">count</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>5 rows × 2 columns</p><table class="data-frame"><thead><tr><th></th><th>target</th><th>count</th></tr><tr><th></th><th title="Float64">Float64</th><th title="Int64">Int64</th></tr></thead><tbody><tr><th>1</th><td>0.5</td><td>251677</td></tr><tr><th>2</th><td>0.25</td><td>100053</td></tr><tr><th>3</th><td>0.75</td><td>100045</td></tr><tr><th>4</th><td>0.0</td><td>25016</td></tr><tr><th>5</th><td>1.0</td><td>25017</td></tr></tbody></table></div>

<h1 id="some-of-the-features-are-very-correlated">Some of the features are very correlated</h1>
<p>Especially within feature groups</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_corrs</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="x">(</span><span class="n">cor</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)])),</span> <span class="n">features</span><span class="x">)</span>
<span class="n">insertcols!</span><span class="x">(</span><span class="n">feature_corrs</span><span class="x">,</span> <span class="mi">1</span><span class="x">,</span> <span class="o">:</span><span class="n">features</span> <span class="o">=&gt;</span> <span class="n">features</span><span class="x">)</span>

<span class="n">first</span><span class="x">(</span><span class="n">feature_corrs</span><span class="x">,</span><span class="mi">5</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>5 rows × 311 columns (omitted printing of 307 columns)</p><table class="data-frame"><thead><tr><th></th><th>features</th><th>feature_intelligence1</th><th>feature_intelligence2</th><th>feature_intelligence3</th></tr><tr><th></th><th title="String">String</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>feature_intelligence1</td><td>1.0</td><td>-0.0141565</td><td>-0.0244041</td></tr><tr><th>2</th><td>feature_intelligence2</td><td>-0.0141565</td><td>1.0</td><td>0.905315</td></tr><tr><th>3</th><td>feature_intelligence3</td><td>-0.0244041</td><td>0.905315</td><td>1.0</td></tr><tr><th>4</th><td>feature_intelligence4</td><td>0.652596</td><td>-0.0280969</td><td>-0.0410859</td></tr><tr><th>5</th><td>feature_intelligence5</td><td>0.0698683</td><td>0.184372</td><td>0.17387</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">first</span><span class="x">(</span><span class="n">stack</span><span class="x">(</span><span class="n">feature_corrs</span><span class="x">),</span> <span class="mi">5</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>5 rows × 3 columns</p><table class="data-frame"><thead><tr><th></th><th>features</th><th>variable</th><th>value</th></tr><tr><th></th><th title="String">String</th><th title="String">String</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>feature_intelligence1</td><td>feature_intelligence1</td><td>1.0</td></tr><tr><th>2</th><td>feature_intelligence2</td><td>feature_intelligence1</td><td>-0.0141565</td></tr><tr><th>3</th><td>feature_intelligence3</td><td>feature_intelligence1</td><td>-0.0244041</td></tr><tr><th>4</th><td>feature_intelligence4</td><td>feature_intelligence1</td><td>0.652596</td></tr><tr><th>5</th><td>feature_intelligence5</td><td>feature_intelligence1</td><td>0.0698683</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tdf</span> <span class="o">=</span> <span class="n">stack</span><span class="x">(</span><span class="n">feature_corrs</span><span class="x">)</span>
<span class="n">tdf</span> <span class="o">=</span> <span class="n">tdf</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">tdf</span><span class="o">.</span><span class="n">variable</span> <span class="o">.&lt;</span> <span class="n">tdf</span><span class="o">.</span><span class="n">features</span><span class="x">,</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>

<span class="n">sort!</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span> <span class="o">:</span><span class="n">value</span><span class="x">)</span>
<span class="n">vcat</span><span class="x">(</span><span class="n">first</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span> <span class="mi">5</span><span class="x">),</span> <span class="n">last</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span> <span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<div class="data-frame"><p>10 rows × 3 columns</p><table class="data-frame"><thead><tr><th></th><th>features</th><th>variable</th><th>value</th></tr><tr><th></th><th title="String">String</th><th title="String">String</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>feature_constitution9</td><td>feature_constitution112</td><td>-0.855008</td></tr><tr><th>2</th><td>feature_constitution46</td><td>feature_constitution33</td><td>-0.83031</td></tr><tr><th>3</th><td>feature_constitution60</td><td>feature_constitution112</td><td>-0.820694</td></tr><tr><th>4</th><td>feature_constitution87</td><td>feature_constitution46</td><td>-0.815888</td></tr><tr><th>5</th><td>feature_constitution33</td><td>feature_constitution112</td><td>-0.759084</td></tr><tr><th>6</th><td>feature_constitution7</td><td>feature_constitution27</td><td>0.94892</td></tr><tr><th>7</th><td>feature_constitution79</td><td>feature_constitution13</td><td>0.949139</td></tr><tr><th>8</th><td>feature_wisdom39</td><td>feature_wisdom31</td><td>0.954984</td></tr><tr><th>9</th><td>feature_wisdom7</td><td>feature_wisdom46</td><td>0.963706</td></tr><tr><th>10</th><td>feature_wisdom2</td><td>feature_wisdom12</td><td>0.968062</td></tr></tbody></table></div>

<h3 id="the-correlation-can-change-over-time">The correlation can change over time</h3>
<p>You can see this by comparing feature correlations on the first half and second half on the training set</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df₁</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&lt;=</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>
<span class="n">df₂</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&gt;</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>

<span class="n">corr₁</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="x">(</span><span class="n">cor</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₁</span><span class="x">,</span> <span class="n">features</span><span class="x">)])),</span> <span class="n">features</span><span class="x">)</span>
<span class="n">insertcols!</span><span class="x">(</span><span class="n">corr₁</span><span class="x">,</span> <span class="mi">1</span><span class="x">,</span> <span class="o">:</span><span class="n">features</span> <span class="o">=&gt;</span> <span class="n">features</span><span class="x">)</span>
<span class="n">corr₁</span> <span class="o">=</span> <span class="n">stack</span><span class="x">(</span><span class="n">corr₁</span><span class="x">)</span>
<span class="n">corr₁</span> <span class="o">=</span> <span class="n">corr₁</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">corr₁</span><span class="o">.</span><span class="n">variable</span> <span class="o">.&lt;</span> <span class="n">corr₁</span><span class="o">.</span><span class="n">features</span><span class="x">,</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>

<span class="n">corr₂</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="x">(</span><span class="n">cor</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="n">features</span><span class="x">)])),</span> <span class="n">features</span><span class="x">)</span>
<span class="n">insertcols!</span><span class="x">(</span><span class="n">corr₂</span><span class="x">,</span> <span class="mi">1</span><span class="x">,</span> <span class="o">:</span><span class="n">features</span> <span class="o">=&gt;</span> <span class="n">features</span><span class="x">)</span>
<span class="n">corr₂</span> <span class="o">=</span> <span class="n">stack</span><span class="x">(</span><span class="n">corr₂</span><span class="x">)</span>
<span class="n">corr₂</span> <span class="o">=</span> <span class="n">corr₂</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">corr₂</span><span class="o">.</span><span class="n">variable</span> <span class="o">.&lt;</span> <span class="n">corr₂</span><span class="o">.</span><span class="n">features</span><span class="x">,</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>

<span class="n">tdf</span> <span class="o">=</span> <span class="n">leftjoin</span><span class="x">(</span><span class="n">corr₁</span><span class="x">,</span> <span class="n">corr₂</span><span class="x">,</span> <span class="n">on</span> <span class="o">=</span> <span class="x">[</span><span class="o">:</span><span class="n">variable</span><span class="x">,</span> <span class="o">:</span><span class="n">features</span><span class="x">],</span> <span class="n">makeunique</span><span class="o">=</span><span class="nb">true</span><span class="x">)</span>
<span class="n">rename!</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span> <span class="x">[</span><span class="o">:</span><span class="n">value</span><span class="x">,</span> <span class="o">:</span><span class="n">value_1</span><span class="x">]</span> <span class="o">.=&gt;</span> <span class="x">[</span><span class="o">:</span><span class="n">corr₁</span><span class="x">,</span> <span class="o">:</span><span class="n">corr₂</span><span class="x">])</span>
<span class="n">tdf</span><span class="o">.</span><span class="n">corr_diff</span> <span class="o">=</span> <span class="n">tdf</span><span class="o">.</span><span class="n">corr₂</span> <span class="o">-</span> <span class="n">tdf</span><span class="o">.</span><span class="n">corr₁</span>
<span class="n">sort!</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span> <span class="o">:</span><span class="n">corr_diff</span><span class="x">)</span>

<span class="n">vcat</span><span class="x">(</span><span class="n">first</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span><span class="mi">5</span><span class="x">),</span> <span class="n">last</span><span class="x">(</span><span class="n">tdf</span><span class="x">,</span><span class="mi">5</span><span class="x">))</span>
</code></pre></div></div>

<div class="data-frame"><p>10 rows × 5 columns</p><table class="data-frame"><thead><tr><th></th><th>features</th><th>variable</th><th>corr₁</th><th>corr₂</th><th>corr_diff</th></tr><tr><th></th><th title="String">String</th><th title="String">String</th><th title="Float64">Float64</th><th title="Union{Missing, Float64}">Float64?</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>feature_intelligence9</td><td>feature_intelligence11</td><td>0.0913519</td><td>-0.128851</td><td>-0.220203</td></tr><tr><th>2</th><td>feature_intelligence10</td><td>feature_dexterity12</td><td>0.548931</td><td>0.343117</td><td>-0.205814</td></tr><tr><th>3</th><td>feature_intelligence11</td><td>feature_dexterity9</td><td>0.0787148</td><td>-0.12707</td><td>-0.205785</td></tr><tr><th>4</th><td>feature_dexterity12</td><td>feature_dexterity1</td><td>0.653528</td><td>0.447942</td><td>-0.205587</td></tr><tr><th>5</th><td>feature_intelligence11</td><td>feature_intelligence10</td><td>0.0750222</td><td>-0.130511</td><td>-0.205534</td></tr><tr><th>6</th><td>feature_wisdom22</td><td>feature_intelligence8</td><td>-0.0883461</td><td>0.117772</td><td>0.206119</td></tr><tr><th>7</th><td>feature_wisdom43</td><td>feature_intelligence4</td><td>-0.102438</td><td>0.103758</td><td>0.206197</td></tr><tr><th>8</th><td>feature_wisdom33</td><td>feature_intelligence4</td><td>-0.0789296</td><td>0.133664</td><td>0.212593</td></tr><tr><th>9</th><td>feature_wisdom43</td><td>feature_intelligence8</td><td>-0.121306</td><td>0.115194</td><td>0.236501</td></tr><tr><th>10</th><td>feature_wisdom33</td><td>feature_intelligence8</td><td>-0.0917593</td><td>0.150549</td><td>0.242308</td></tr></tbody></table></div>

<h2 id="some-features-are-predictive-on-their-own">Some features are predictive on their own</h2>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_scores</span> <span class="o">=</span> 
    <span class="kt">Dict</span><span class="x">(</span><span class="n">feature</span> <span class="o">=&gt;</span> <span class="n">numerai_score</span><span class="x">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">feature</span><span class="x">],</span> <span class="n">df</span><span class="x">)</span> 
    <span class="k">for</span> <span class="n">feature</span> <span class="k">in</span> <span class="n">features</span><span class="x">);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sort</span><span class="x">(</span><span class="n">collect</span><span class="x">(</span><span class="n">feature_scores</span><span class="x">),</span> <span class="n">by</span><span class="o">=</span><span class="n">x</span><span class="o">-&gt;</span><span class="n">x</span><span class="x">[</span><span class="mi">2</span><span class="x">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>310-element Vector{Pair{String, Float64}}:
      "feature_dexterity7" =&gt; -0.011504914975281387
      "feature_dexterity6" =&gt; -0.011161569760516648
      "feature_dexterity4" =&gt; -0.011051275935746707
      "feature_charisma69" =&gt; -0.010221311263804505
     "feature_dexterity11" =&gt; -0.010198611285978189
       "feature_charisma9" =&gt; -0.01005025481510148
     "feature_dexterity12" =&gt; -0.008647990681418269
     "feature_dexterity14" =&gt; -0.008611934226827449
      "feature_dexterity3" =&gt; -0.007607475423078082
  "feature_constitution91" =&gt; -0.007343474478571397
      "feature_dexterity8" =&gt; -0.0072798010318430835
  "feature_constitution56" =&gt; -0.007206474137472462
 "feature_constitution110" =&gt; -0.007154545491821277
                           ⋮
       "feature_strength4" =&gt; 0.010184232051437234
      "feature_charisma81" =&gt; 0.010224703123621929
      "feature_charisma46" =&gt; 0.01039946229179084
      "feature_charisma66" =&gt; 0.010507207995266913
      "feature_charisma54" =&gt; 0.010507614931830764
       "feature_charisma6" =&gt; 0.010580151207446348
      "feature_charisma76" =&gt; 0.010608014161745269
      "feature_charisma18" =&gt; 0.010697616377184683
      "feature_charisma19" =&gt; 0.01071636820945142
      "feature_charisma37" =&gt; 0.01089177370157534
      "feature_strength14" =&gt; 0.01160884774563975
      "feature_strength34" =&gt; 0.012487781133717898
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Single features do not work consistently though</span>

<span class="n">by_era_correlation</span> <span class="o">=</span> 
    <span class="n">sort</span><span class="x">(</span><span class="kt">Dict</span><span class="x">(</span><span class="n">values</span><span class="x">(</span><span class="n">erano</span><span class="x">)[</span><span class="mi">1</span><span class="x">]</span> <span class="o">=&gt;</span> <span class="n">cor</span><span class="x">(</span><span class="n">tdf</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">tdf</span><span class="o">.</span><span class="n">feature_strength34</span><span class="x">)</span>
         <span class="k">for</span> <span class="x">(</span><span class="n">erano</span><span class="x">,</span> <span class="n">tdf</span><span class="x">)</span> <span class="k">in</span> <span class="n">pairs</span><span class="x">(</span><span class="n">groupby</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="o">:</span><span class="n">erano</span><span class="x">))))</span>
    
<span class="n">plot</span><span class="x">(</span><span class="n">by_era_correlation</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="images/analysis_and_tips_julia_18_0.svg" alt="svg" /></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># With a rolling 10 era average you can see some trends</span>

<span class="k">function</span><span class="nf"> rolling_mean</span><span class="x">(</span><span class="n">arr</span><span class="x">,</span> <span class="n">n</span><span class="x">)</span>
    <span class="n">rs</span> <span class="o">=</span> <span class="n">cumsum</span><span class="x">(</span><span class="n">arr</span><span class="x">)[</span><span class="n">n</span><span class="o">:</span><span class="k">end</span><span class="x">]</span> <span class="o">.-</span> <span class="n">cumsum</span><span class="x">([</span><span class="mf">0.0</span><span class="x">;</span> <span class="n">arr</span><span class="x">])[</span><span class="mi">1</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="n">n</span><span class="x">]</span>
    <span class="k">return</span> <span class="n">rs</span> <span class="o">./</span> <span class="n">n</span>
<span class="k">end</span>

<span class="n">n_window</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">plot</span><span class="x">(</span><span class="kt">Dict</span><span class="x">(</span><span class="n">zip</span><span class="x">(</span><span class="n">collect</span><span class="x">(</span><span class="n">n_window</span><span class="o">-</span><span class="mi">1</span><span class="o">:</span><span class="n">length</span><span class="x">(</span><span class="n">by_era_correlation</span><span class="x">)),</span> 
        <span class="n">rolling_mean</span><span class="x">(</span><span class="n">collect</span><span class="x">(</span><span class="n">values</span><span class="x">(</span><span class="n">by_era_correlation</span><span class="x">)),</span><span class="n">n_window</span><span class="x">))))</span>
</code></pre></div></div>

<p><img src="images/analysis_and_tips_julia_19_0.svg" alt="svg" /></p>

<h1 id="gotcha-mse-looks-worse-than-correlation-out-of-sample">Gotcha: MSE looks worse than correlation out of sample</h1>
<p>Models will generally be overconfident, so even if they are good at ranking rows, the Mean-Squared-Error of the residuals could be larger than event the Mean-Squared-Error of the target (r-squared&lt;0)</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df₁</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&lt;=</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>
<span class="n">df₂</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&gt;</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">];</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This is using MLJ, Julia's homegrown machine-learning library</span>

<span class="n">Linear</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">LinearRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">MLJLinearModels</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">Linear</span><span class="x">()</span>

<span class="n">lin₁</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">linear</span><span class="x">,</span> <span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₁</span><span class="x">,</span> <span class="n">features</span><span class="x">)],</span> <span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">lin₁</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">)</span>

<span class="n">lin₂</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">linear</span><span class="x">,</span> <span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="n">features</span><span class="x">)],</span> <span class="n">df₂</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">lin₂</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Note in particular that the R-squared of (train_on_1, eval_on_2) is slightly negative!</span>

<span class="n">r2₁</span> <span class="o">=</span> <span class="x">[</span>
    <span class="n">r2_score</span><span class="x">(</span><span class="n">dfₓ</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">dfₓ</span><span class="x">,</span> <span class="n">features</span><span class="x">)]))</span>
        <span class="k">for</span> <span class="n">dfₓ</span> <span class="k">in</span> <span class="x">[</span><span class="n">df₁</span><span class="x">,</span> <span class="n">df₂</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">model</span> <span class="k">in</span> <span class="x">[</span><span class="n">lin₁</span><span class="x">,</span> <span class="n">lin₂</span><span class="x">]]</span>

<span class="n">DataFrame</span><span class="x">(</span><span class="n">reshape</span><span class="x">(</span><span class="n">r2₁</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="x">[</span><span class="s">"eval_on_1"</span><span class="x">,</span><span class="s">"eval_on_2"</span><span class="x">])</span>
</code></pre></div></div>

<div class="data-frame"><p>2 rows × 2 columns</p><table class="data-frame"><thead><tr><th></th><th>eval_on_1</th><th>eval_on_2</th></tr><tr><th></th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.00409275</td><td>-0.000543157</td></tr><tr><th>2</th><td>0.000574622</td><td>0.00315522</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Note in particular that the correlation of (train_on_1, eval_on_2) is quite decent (comparatively)</span>
<span class="n">corrs</span> <span class="o">=</span> <span class="x">[</span>
    <span class="n">numerai_score</span><span class="x">(</span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">dfₓ</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">dfₓ</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">)</span>
        <span class="k">for</span> <span class="n">dfₓ</span> <span class="k">in</span> <span class="x">[</span><span class="n">df₁</span><span class="x">,</span> <span class="n">df₂</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">model</span> <span class="k">in</span> <span class="x">[</span><span class="n">lin₁</span><span class="x">,</span> <span class="n">lin₂</span><span class="x">]]</span>

<span class="n">DataFrame</span><span class="x">(</span><span class="n">reshape</span><span class="x">(</span><span class="n">corrs</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="x">[</span><span class="s">"eval_on_1"</span><span class="x">,</span><span class="s">"eval_on_2"</span><span class="x">])</span>
</code></pre></div></div>

<div class="data-frame"><p>2 rows × 2 columns</p><table class="data-frame"><thead><tr><th></th><th>eval_on_1</th><th>eval_on_2</th></tr><tr><th></th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.058282</td><td>0.0287217</td></tr><tr><th>2</th><td>0.0319412</td><td>0.0528229</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This can be be run with XGB as well</span>

<span class="n">XGB</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">XGBoostRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">XGBoost</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGB</span><span class="x">()</span>

<span class="n">xgb₁</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">xgb</span><span class="x">,</span> <span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₁</span><span class="x">,</span> <span class="n">features</span><span class="x">)],</span> <span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">xgb₁</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">)</span>

<span class="n">xgb₂</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">xgb</span><span class="x">,</span> <span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="n">features</span><span class="x">)],</span> <span class="n">df₂</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">xgb₂</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">r2₂</span> <span class="o">=</span> <span class="x">[</span>
    <span class="n">r2_score</span><span class="x">(</span><span class="n">dfₓ</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">dfₓ</span><span class="x">,</span> <span class="n">features</span><span class="x">)]))</span>
        <span class="k">for</span> <span class="n">dfₓ</span> <span class="k">in</span> <span class="x">[</span><span class="n">df₁</span><span class="x">,</span> <span class="n">df₂</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">model</span> <span class="k">in</span> <span class="x">[</span><span class="n">xgb₁</span><span class="x">,</span> <span class="n">xgb₂</span><span class="x">]]</span>

<span class="n">DataFrame</span><span class="x">(</span><span class="n">reshape</span><span class="x">(</span><span class="n">r2₂</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="x">[</span><span class="s">"eval_on_1"</span><span class="x">,</span><span class="s">"eval_on_2"</span><span class="x">])</span>
</code></pre></div></div>

<div class="data-frame"><p>2 rows × 2 columns</p><table class="data-frame"><thead><tr><th></th><th>eval_on_1</th><th>eval_on_2</th></tr><tr><th></th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.123117</td><td>-0.0237936</td></tr><tr><th>2</th><td>-0.0199959</td><td>0.12788</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corrs2</span> <span class="o">=</span> <span class="x">[</span>
    <span class="n">numerai_score</span><span class="x">(</span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">dfₓ</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">dfₓ</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">dfₓ</span><span class="x">)</span>
        <span class="k">for</span> <span class="n">dfₓ</span> <span class="k">in</span> <span class="x">[</span><span class="n">df₁</span><span class="x">,</span> <span class="n">df₂</span><span class="x">]</span>
    <span class="k">for</span> <span class="n">model</span> <span class="k">in</span> <span class="x">[</span><span class="n">xgb₁</span><span class="x">,</span> <span class="n">xgb₂</span><span class="x">]]</span>

<span class="n">DataFrame</span><span class="x">(</span><span class="n">reshape</span><span class="x">(</span><span class="n">corrs2</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">2</span><span class="x">),</span> <span class="x">[</span><span class="s">"eval_on_1"</span><span class="x">,</span><span class="s">"eval_on_2"</span><span class="x">])</span>
</code></pre></div></div>

<div class="data-frame"><p>2 rows × 2 columns</p><table class="data-frame"><thead><tr><th></th><th>eval_on_1</th><th>eval_on_2</th></tr><tr><th></th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.383874</td><td>0.0240443</td></tr><tr><th>2</th><td>0.0229365</td><td>0.392287</td></tr></tbody></table></div>

<h1 id="gotcha--0-1-are-noticeably-different-from-025-075">Gotcha:  {0, 1} are noticeably different from {0.25, 0.75}</h1>
<p>This makes training a classifier one-versus-rest behave counterintuitively.</p>

<p>Specifically, the 0-vs-rest and 1-vs-rest classifiers seem to learn how to pick out extreme targets, and their predictions are the most correlated</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Mostly doing this in Scikitlearn.JL due to no predict_proba (that I'm aware of) in MLJ</span>

<span class="n">logistic</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="x">()</span>
<span class="n">ScikitLearn</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">logistic</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">convert</span><span class="o">.</span><span class="x">(</span><span class="kt">Int</span><span class="x">,</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">*</span><span class="mi">4</span><span class="x">))</span>
<span class="n">ScikitLearn</span><span class="o">.</span><span class="n">score</span><span class="x">(</span><span class="n">logistic</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">convert</span><span class="o">.</span><span class="x">(</span><span class="kt">Int</span><span class="x">,</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="o">*</span><span class="mi">4</span><span class="x">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>C:\Users\Justin\.julia\conda\3\lib\site-packages\sklearn\linear_model\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(





0.5012315467270351
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The first and last class are highly correlated</span>
<span class="n">log_corrs</span> <span class="o">=</span> <span class="n">cor</span><span class="x">(</span><span class="n">transpose</span><span class="x">(</span><span class="n">ScikitLearn</span><span class="o">.</span><span class="n">predict_proba</span><span class="x">(</span><span class="n">logistic</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]))),</span> <span class="n">dims</span><span class="o">=</span><span class="mi">2</span><span class="x">)</span>
<span class="n">display</span><span class="x">(</span><span class="n">log_corrs</span><span class="x">)</span>

<span class="n">heatmap</span><span class="x">(</span><span class="n">log_corrs</span><span class="x">,</span>  <span class="n">c</span><span class="o">=</span><span class="n">palette</span><span class="x">(</span><span class="o">:</span><span class="n">RdYlGn</span><span class="x">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5×5 Matrix{Float64}:
  1.0        0.468155  -0.903881   0.42197    0.947252
  0.468155   1.0       -0.704718   0.517207   0.428423
 -0.903881  -0.704718   1.0       -0.71843   -0.914418
  0.42197    0.517207  -0.71843    1.0        0.498854
  0.947252   0.428423  -0.914418   0.498854   1.0
</code></pre></div></div>

<p><img src="images/analysis_and_tips_julia_30_1.svg" alt="svg" /></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># In-sample correlation</span>

<span class="n">prob_matrix</span> <span class="o">=</span> <span class="n">ScikitLearn</span><span class="o">.</span><span class="n">predict_proba</span><span class="x">(</span><span class="n">logistic</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]))</span>
<span class="n">classes</span> <span class="o">=</span> <span class="n">logistic</span><span class="o">.</span><span class="n">classes_</span>
<span class="n">numerai_score</span><span class="x">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">prob_matrix</span> <span class="o">*</span> <span class="n">classes</span><span class="x">,</span> <span class="n">df</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.050658929537343786
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># A standard linear model has a slightly higher correlation</span>
<span class="n">linear</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="x">()</span>
<span class="n">ScikitLearn</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">linear</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">ScikitLearn</span><span class="o">.</span><span class="n">score</span><span class="x">(</span><span class="n">linear</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">ScikitLearn</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">linear</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]))</span>
<span class="n">numerai_score</span><span class="x">(</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">preds</span><span class="x">,</span> <span class="n">df</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.05107803901831943
</code></pre></div></div>

<h1 id="gotcha-eras-are-homogenous-but-different-from-each-other">Gotcha: eras are homogenous, but different from each other</h1>
<h2 id="random-cross-validation-will-look-much-better-than-cross-validating-by-era">Random cross-validation will look much better than cross-validating by era</h2>

<p>Even for a simple linear model, taking a random shuffle reports a correlation of 4.3%, but a time series split reports a lower score of 3.4%</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#linear = LinearRegression()</span>
<span class="c">#ScikitLearn.fit!(linear, Matrix(df[!, names(df, features)]), df.target)</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">crossvalidators</span> <span class="o">=</span> <span class="x">[</span><span class="n">KFold</span><span class="x">(</span><span class="mi">5</span><span class="x">),</span> <span class="n">KFold</span><span class="x">(</span><span class="mi">5</span><span class="x">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="nb">true</span><span class="x">),</span> <span class="n">GroupKFold</span><span class="x">(</span><span class="mi">5</span><span class="x">),</span> <span class="n">TimeSeriesSplit</span><span class="x">(</span><span class="mi">5</span><span class="x">)]</span>

<span class="k">for</span> <span class="n">cv</span> <span class="k">in</span> <span class="n">crossvalidators</span>
    <span class="n">println</span><span class="x">(</span><span class="n">cv</span><span class="x">)</span>
    <span class="n">println</span><span class="x">(</span>
        <span class="n">mean</span><span class="x">(</span>
            <span class="n">cross_val_score</span><span class="x">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="x">(),</span>
                <span class="n">X</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">,</span>
                <span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span><span class="x">,</span>
                <span class="n">groups</span> <span class="o">=</span> <span class="n">eras</span><span class="x">,</span>
                <span class="n">scoring</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="x">(</span><span class="n">cor</span><span class="x">,</span> <span class="n">greater_is_better</span> <span class="o">=</span> <span class="nb">true</span><span class="x">)</span>
            <span class="x">)</span>
        <span class="x">)</span>
    <span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PyObject KFold(n_splits=5, random_state=None, shuffle=False)
0.03332624500455265
PyObject KFold(n_splits=5, random_state=None, shuffle=True)
0.039196207369748895
PyObject GroupKFold(n_splits=5)
0.03475937229926111
PyObject TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)
0.030947709608331396
</code></pre></div></div>

<h2 id="eras-can-be-more-or-less-applicable-to-other-eras">Eras can be more or less applicable to other eras</h2>
<p>You can test this be splitting the eras into blocks of 10, training on each block, and evaluating on each other block.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eras10</span> <span class="o">=</span> <span class="x">(</span><span class="n">eras</span> <span class="o">.÷</span> <span class="mi">10</span><span class="x">)</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">countmap</span><span class="x">(</span><span class="n">eras10</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Dict{Int64, Int64} with 13 entries:
  20  =&gt; 37444
  110 =&gt; 45070
  60  =&gt; 46831
  30  =&gt; 41101
  0   =&gt; 24515
  80  =&gt; 43971
  90  =&gt; 45609
  40  =&gt; 43439
  70  =&gt; 40403
  50  =&gt; 48186
  10  =&gt; 34600
  120 =&gt; 4532
  100 =&gt; 46107
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">gdf</span> <span class="o">=</span> <span class="n">copy</span><span class="x">(</span><span class="n">df</span><span class="x">)</span>
<span class="n">gdf</span><span class="x">[</span><span class="o">:</span><span class="x">,</span> <span class="o">:</span><span class="n">eras10</span> <span class="x">]</span> <span class="o">=</span> <span class="n">eras10</span>
<span class="n">gdf</span> <span class="o">=</span> <span class="n">groupby</span><span class="x">(</span><span class="n">filter</span><span class="x">(</span><span class="n">row</span> <span class="o">-&gt;</span> <span class="n">row</span><span class="x">[</span><span class="o">:</span><span class="n">eras10</span><span class="x">]</span> <span class="o">&lt;</span> <span class="mi">120</span><span class="x">,</span> <span class="n">gdf</span><span class="x">),</span> <span class="o">:</span><span class="n">eras10</span><span class="x">);</span>
<span class="n">results10</span> <span class="o">=</span> <span class="n">DataFrame</span><span class="x">(</span><span class="n">train_era</span> <span class="o">=</span> <span class="kt">Int32</span><span class="x">[],</span> <span class="n">test_era</span> <span class="o">=</span> <span class="kt">Int32</span><span class="x">[],</span> <span class="n">value</span> <span class="o">=</span> <span class="kt">Float32</span><span class="x">[])</span>

<span class="k">for</span> <span class="n">train_era</span> <span class="k">in</span> <span class="n">keys</span><span class="x">(</span><span class="n">gdf</span><span class="x">)</span>
    
    <span class="n">println</span><span class="x">(</span><span class="n">train_era</span><span class="x">[</span><span class="mi">1</span><span class="x">])</span>
    
    <span class="n">gdf₁</span> <span class="o">=</span> <span class="n">gdf</span><span class="x">[</span><span class="n">train_era</span><span class="x">]</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="x">()</span>
    <span class="n">ScikitLearn</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">gdf₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">gdf₁</span><span class="x">,</span> <span class="n">features</span><span class="x">)]),</span> <span class="n">gdf₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
    
    <span class="k">for</span> <span class="n">test_era</span> <span class="k">in</span> <span class="n">keys</span><span class="x">(</span><span class="n">gdf</span><span class="x">)</span>
        
        <span class="n">gdf₂</span> <span class="o">=</span> <span class="n">gdf</span><span class="x">[</span><span class="n">test_era</span><span class="x">]</span>
        
        <span class="n">push!</span><span class="x">(</span><span class="n">results10</span><span class="x">,</span> <span class="x">[</span><span class="n">train_era</span><span class="x">[</span><span class="mi">1</span><span class="x">],</span> 
                         <span class="n">test_era</span><span class="x">[</span><span class="mi">1</span><span class="x">],</span> 
                         <span class="n">cor</span><span class="x">(</span><span class="n">gdf₂</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">ScikitLearn</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">gdf₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">names</span><span class="x">(</span><span class="n">gdf₂</span><span class="x">,</span> <span class="n">features</span><span class="x">)])))])</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0
10
20
30
40
50
60
70
80
90
100
110
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results_df</span> <span class="o">=</span> <span class="n">unstack</span><span class="x">(</span><span class="n">results10</span><span class="x">,</span> <span class="o">:</span><span class="n">test_era</span><span class="x">,</span> <span class="o">:</span><span class="n">value</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>12 rows × 13 columns (omitted printing of 6 columns)</p><table class="data-frame"><thead><tr><th></th><th>train_era</th><th>0</th><th>10</th><th>20</th><th>30</th><th>40</th><th>50</th></tr><tr><th></th><th title="Int32">Int32</th><th title="Union{Missing, Float32}">Float32?</th><th title="Union{Missing, Float32}">Float32?</th><th title="Union{Missing, Float32}">Float32?</th><th title="Union{Missing, Float32}">Float32?</th><th title="Union{Missing, Float32}">Float32?</th><th title="Union{Missing, Float32}">Float32?</th></tr></thead><tbody><tr><th>1</th><td>0</td><td>0.14615</td><td>0.0321283</td><td>0.0354025</td><td>0.0287675</td><td>0.0221984</td><td>0.00701235</td></tr><tr><th>2</th><td>10</td><td>0.0421759</td><td>0.114813</td><td>0.0287059</td><td>0.0298504</td><td>0.0336937</td><td>0.00471899</td></tr><tr><th>3</th><td>20</td><td>0.0431496</td><td>0.0334976</td><td>0.113055</td><td>0.0366226</td><td>0.0167489</td><td>0.00565709</td></tr><tr><th>4</th><td>30</td><td>0.0357169</td><td>0.0339307</td><td>0.0396031</td><td>0.109884</td><td>0.0402888</td><td>0.0208269</td></tr><tr><th>5</th><td>40</td><td>0.035735</td><td>0.0417183</td><td>0.0204626</td><td>0.0403498</td><td>0.100257</td><td>0.0144214</td></tr><tr><th>6</th><td>50</td><td>0.015032</td><td>0.00959667</td><td>0.00685722</td><td>0.0242685</td><td>0.0151326</td><td>0.104185</td></tr><tr><th>7</th><td>60</td><td>0.00690366</td><td>0.0159851</td><td>0.00419466</td><td>0.0195585</td><td>0.012405</td><td>0.00967648</td></tr><tr><th>8</th><td>70</td><td>0.034285</td><td>0.0252239</td><td>0.0220385</td><td>0.0285308</td><td>0.0232155</td><td>0.00198308</td></tr><tr><th>9</th><td>80</td><td>0.0395826</td><td>0.0268682</td><td>0.0115186</td><td>0.0217091</td><td>0.0177472</td><td>0.00252007</td></tr><tr><th>10</th><td>90</td><td>0.0328201</td><td>0.029052</td><td>0.0229233</td><td>0.031348</td><td>0.0199844</td><td>0.0100413</td></tr><tr><th>11</th><td>100</td><td>0.0283381</td><td>0.0179835</td><td>0.0217198</td><td>0.00991935</td><td>0.00779132</td><td>0.0120947</td></tr><tr><th>12</th><td>110</td><td>0.00181083</td><td>0.0183579</td><td>0.00941574</td><td>0.0067019</td><td>0.0147348</td><td>0.0164994</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">heatmap</span><span class="x">(</span><span class="n">clamp!</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">select</span><span class="x">(</span><span class="n">results_df</span><span class="x">,</span> <span class="n">Not</span><span class="x">(</span><span class="o">:</span><span class="n">train_era</span><span class="x">))),</span> <span class="o">-.</span><span class="mi">04</span><span class="x">,</span> <span class="o">.</span><span class="mi">04</span><span class="x">),</span>  <span class="n">c</span><span class="o">=</span><span class="n">palette</span><span class="x">(</span><span class="o">:</span><span class="n">RdYlGn</span><span class="x">))</span>
</code></pre></div></div>

<p><img src="images/analysis_and_tips_julia_40_0.svg" alt="svg" /></p>

<p>Here is an advanced paper that talks about generalization.
Eras can be thought about in the same way that “distributions” or “environments” are talked about here
https://arxiv.org/pdf/1907.02893.pdf</p>

<h2 id="gotcha-since-the-signal-to-noise-ratio-is-so-low-models-can-take-many-more-iterations-than-expected-and-have-scarily-high-in-sample-performance">Gotcha: Since the signal-to-noise ratio is so low, models can take many more iterations than expected, and have scarily high in-sample performance</h2>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df₁</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&lt;=</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>
<span class="n">df₂</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&gt;</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">];</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> our_score</span><span class="x">(</span><span class="n">preds</span><span class="x">,</span> <span class="n">dtrain</span><span class="x">)</span>
    <span class="k">return</span> <span class="s">"score"</span><span class="x">,</span> <span class="n">cor</span><span class="x">(</span><span class="n">get_info</span><span class="x">(</span><span class="n">dtrain</span><span class="x">,</span> <span class="s">"label"</span><span class="x">),</span> <span class="n">preds</span><span class="x">)</span>
<span class="k">end</span>

<span class="n">dtrain</span> <span class="o">=</span> <span class="n">DMatrix</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]),</span> <span class="n">label</span><span class="o">=</span><span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">DMatrix</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]),</span> <span class="n">label</span><span class="o">=</span><span class="n">df₂</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">dall</span> <span class="o">=</span> <span class="n">DMatrix</span><span class="x">(</span><span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]),</span> <span class="n">label</span><span class="o">=</span><span class="n">df</span><span class="o">.</span><span class="n">target</span><span class="x">);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This part I wasn't able to replicate perfectly, XGBoost on Julia seems to(?) lack an evals_result to push the data into</span>
<span class="c"># the source code shows only that it prints to stderr - one could redirect it to an IOBuffer and regex parse it into an</span>
<span class="c"># array but realistically the amount of effort isn't worth it, since one can clearly see the out-of-sample performance </span>
<span class="c"># differneces purely from the numbers printed</span>

<span class="n">param</span> <span class="o">=</span> <span class="kt">Dict</span><span class="x">(</span>
    <span class="s">"eta"</span> <span class="o">=&gt;</span> <span class="mf">0.1</span><span class="x">,</span>
    <span class="s">"max_depth"</span> <span class="o">=&gt;</span> <span class="mi">3</span><span class="x">,</span>
    <span class="s">"objective"</span> <span class="o">=&gt;</span> <span class="s">"reg:squarederror"</span><span class="x">,</span>
    <span class="s">"eval_metric"</span> <span class="o">=&gt;</span> <span class="s">"rmse"</span>
<span class="x">)</span>


<span class="n">xgboost</span><span class="x">(</span><span class="n">dtrain</span><span class="x">,</span>
    <span class="mi">100</span><span class="x">,</span>
    <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="x">,</span> 
    <span class="n">watchlist</span> <span class="o">=</span> <span class="x">[(</span><span class="n">dtrain</span><span class="x">,</span> <span class="s">"train"</span><span class="x">),</span> <span class="x">(</span><span class="n">dtest</span><span class="x">,</span> <span class="s">"test"</span><span class="x">)],</span> 
    <span class="n">feval</span> <span class="o">=</span> <span class="n">our_score</span>
<span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1]	train-score:0.034205	test-score:0.013370
[2]	train-score:0.042116	test-score:0.018210
[3]	train-score:0.044523	test-score:0.020057
[4]	train-score:0.046625	test-score:0.020591
[5]	train-score:0.047456	test-score:0.021075
[6]	train-score:0.050244	test-score:0.022334
[7]	train-score:0.053165	test-score:0.023862
[8]	train-score:0.053749	test-score:0.024308
[9]	train-score:0.055734	test-score:0.025105
[10]	train-score:0.056863	test-score:0.025744
[11]	train-score:0.057717	test-score:0.025711
[12]	train-score:0.058456	test-score:0.026579
[13]	train-score:0.059670	test-score:0.027121
[14]	train-score:0.061333	test-score:0.027169
[15]	train-score:0.062278	test-score:0.027445
[16]	train-score:0.063603	test-score:0.028017
[17]	train-score:0.063934	test-score:0.028256
[18]	train-score:0.065052	test-score:0.028822
[19]	train-score:0.066291	test-score:0.029125
[20]	train-score:0.067134	test-score:0.028689
[21]	train-score:0.068495	test-score:0.029119
[22]	train-score:0.069201	test-score:0.029029
[23]	train-score:0.070425	test-score:0.029236
[24]	train-score:0.071568	test-score:0.029508
[25]	train-score:0.072137	test-score:0.029973
[26]	train-score:0.072909	test-score:0.029859
[27]	train-score:0.073970	test-score:0.030114
[28]	train-score:0.074752	test-score:0.030397
[29]	train-score:0.075204	test-score:0.030447
[30]	train-score:0.075893	test-score:0.030690
[31]	train-score:0.076471	test-score:0.030660
[32]	train-score:0.076987	test-score:0.030473
[33]	train-score:0.077460	test-score:0.030752
[34]	train-score:0.077869	test-score:0.030746
[35]	train-score:0.078555	test-score:0.031091
[36]	train-score:0.078825	test-score:0.031524
[37]	train-score:0.079270	test-score:0.031895
[38]	train-score:0.079848	test-score:0.031853
[39]	train-score:0.080204	test-score:0.031560
[40]	train-score:0.080906	test-score:0.031729
[41]	train-score:0.081367	test-score:0.031682
[42]	train-score:0.082308	test-score:0.031711
[43]	train-score:0.082807	test-score:0.031745
[44]	train-score:0.083513	test-score:0.032172
[45]	train-score:0.084038	test-score:0.032111
[46]	train-score:0.084551	test-score:0.032103
[47]	train-score:0.085371	test-score:0.032024
[48]	train-score:0.086145	test-score:0.032008
[49]	train-score:0.086439	test-score:0.031888
[50]	train-score:0.086804	test-score:0.031782
[51]	train-score:0.087273	test-score:0.032083
[52]	train-score:0.087956	test-score:0.032262
[53]	train-score:0.088026	test-score:0.032434
[54]	train-score:0.088556	test-score:0.032589
[55]	train-score:0.088790	test-score:0.032618
[56]	train-score:0.089321	test-score:0.032612
[57]	train-score:0.089829	test-score:0.032729
[58]	train-score:0.090087	test-score:0.032762
[59]	train-score:0.090309	test-score:0.032838
[60]	train-score:0.091052	test-score:0.032866
[61]	train-score:0.091601	test-score:0.032716
[62]	train-score:0.092032	test-score:0.032689
[63]	train-score:0.092394	test-score:0.032566
[64]	train-score:0.092747	test-score:0.032685
[65]	train-score:0.093236	test-score:0.032907
[66]	train-score:0.093703	test-score:0.032696
[67]	train-score:0.094115	test-score:0.032824
[68]	train-score:0.094518	test-score:0.032690
[69]	train-score:0.094853	test-score:0.032965
[70]	train-score:0.095340	test-score:0.032935
[71]	train-score:0.095867	test-score:0.033131
[72]	train-score:0.096333	test-score:0.033031
[73]	train-score:0.096724	test-score:0.032923
[74]	train-score:0.096926	test-score:0.032929
[75]	train-score:0.097358	test-score:0.032930
[76]	train-score:0.097798	test-score:0.033127
[77]	train-score:0.098150	test-score:0.033046
[78]	train-score:0.098434	test-score:0.033101
[79]	train-score:0.098696	test-score:0.033058
[80]	train-score:0.099147	test-score:0.033266
[81]	train-score:0.099522	test-score:0.033358
[82]	train-score:0.099870	test-score:0.033457
[83]	train-score:0.100308	test-score:0.033465
[84]	train-score:0.100698	test-score:0.033422
[85]	train-score:0.101070	test-score:0.033549
[86]	train-score:0.101323	test-score:0.033512
[87]	train-score:0.101738	test-score:0.033682
[88]	train-score:0.101921	test-score:0.033735
[89]	train-score:0.102211	test-score:0.033773
[90]	train-score:0.102537	test-score:0.033706
[91]	train-score:0.102779	test-score:0.033658
[92]	train-score:0.103363	test-score:0.033927
[93]	train-score:0.103683	test-score:0.033817
[94]	train-score:0.104193	test-score:0.033676
[95]	train-score:0.104675	test-score:0.033660
[96]	train-score:0.104912	test-score:0.033559
[97]	train-score:0.105215	test-score:0.033580
[98]	train-score:0.105604	test-score:0.033538
[99]	train-score:0.105853	test-score:0.033650
[100]	train-score:0.106177	test-score:0.033704





Booster(Ptr{Nothing} @0x000000018aa6a970)
</code></pre></div></div>

<h1 id="the-results-are-sensitive-to-the-choice-of-parameters-which-should-be-picked-through-cross-validation">The results are sensitive to the choice of parameters, which should be picked through cross-validation</h1>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df₁</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&lt;=</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">]</span>
<span class="n">df₂</span> <span class="o">=</span> <span class="n">df</span><span class="x">[</span><span class="n">coalesce</span><span class="o">.</span><span class="x">(</span><span class="n">eras</span> <span class="o">.&gt;</span> <span class="n">median</span><span class="x">(</span><span class="n">eras</span><span class="x">),</span> <span class="nb">false</span><span class="x">),</span> <span class="o">:</span><span class="x">];</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">XGB</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">XGBoostRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">XGBoost</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
<span class="n">Linear</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">LinearRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">MLJLinearModels</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
<span class="n">Elastic</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">ElasticNetRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">MLJLinearModels</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ElasticNetRegressor
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">models</span> <span class="o">=</span> <span class="n">vcat</span><span class="x">(</span>
    <span class="x">[</span><span class="n">Linear</span><span class="x">()],</span>
    <span class="x">[</span><span class="n">Elastic</span><span class="x">(</span><span class="n">lambda</span> <span class="o">=</span> <span class="n">λ</span><span class="x">)</span> <span class="k">for</span> <span class="n">λ</span> <span class="k">in</span> <span class="x">[</span><span class="mf">0.01</span><span class="x">,</span> <span class="mf">0.005</span><span class="x">,</span> <span class="mf">0.002</span><span class="x">,</span> <span class="mf">0.001</span><span class="x">,</span> <span class="mf">0.0005</span><span class="x">,</span> <span class="mf">0.0002</span><span class="x">,</span> <span class="mf">0.0001</span><span class="x">,</span> <span class="mf">0.00005</span><span class="x">,</span> <span class="mf">0.00002</span><span class="x">,</span> <span class="mf">0.00001</span><span class="x">]],</span>
    <span class="x">[</span><span class="n">XGB</span><span class="x">()],</span>
    <span class="x">[</span><span class="n">XGB</span><span class="x">(</span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.01</span><span class="x">,</span> <span class="n">num_round</span><span class="o">=</span><span class="mi">1000</span><span class="x">)],</span>
    <span class="x">[</span><span class="n">XGB</span><span class="x">(</span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.01</span><span class="x">,</span> <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.1</span><span class="x">,</span> <span class="n">num_round</span><span class="o">=</span><span class="mi">1000</span><span class="x">)],</span>
    <span class="x">[</span><span class="n">XGB</span><span class="x">(</span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.01</span><span class="x">,</span> <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.1</span><span class="x">,</span> <span class="n">num_round</span><span class="o">=</span><span class="mi">1000</span><span class="x">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="x">)],</span>
    <span class="x">[</span><span class="n">XGB</span><span class="x">(</span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.001</span><span class="x">,</span> <span class="n">colsample_bytree</span><span class="o">=</span><span class="mf">0.1</span><span class="x">,</span> <span class="n">num_round</span><span class="o">=</span><span class="mi">1000</span><span class="x">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="x">)]</span>
<span class="x">);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">model</span> <span class="k">in</span> <span class="n">models</span>
    <span class="n">print</span><span class="x">(</span><span class="s">" -- "</span><span class="x">,</span> <span class="n">model</span><span class="x">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="x">)</span>
    <span class="n">mach</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">model</span><span class="x">,</span> <span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">],</span> <span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
    <span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">mach</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">)</span>
    <span class="n">outsample</span> <span class="o">=</span> <span class="n">numerai_score</span><span class="x">(</span><span class="n">df₂</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">mach</span><span class="x">,</span> <span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]),</span> <span class="n">df₂</span><span class="x">)</span>
    <span class="n">insample</span> <span class="o">=</span> <span class="n">numerai_score</span><span class="x">(</span><span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">,</span> <span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">mach</span><span class="x">,</span> <span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]),</span> <span class="n">df₁</span><span class="x">)</span>
    <span class="n">print</span><span class="x">(</span><span class="s">"outsample: </span><span class="si">$</span><span class="s">outsample, insample: </span><span class="si">$</span><span class="s">insample"</span><span class="x">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> -- [34mLinearRegressor @423[39m
outsample: 0.028025599207339144, insample: 0.06275168899240204
 -- [34mElasticNetRegressor @297[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651106932304964, insample: 0.061801048380003165
 -- [34mElasticNetRegressor @124[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651115862462477, insample: 0.061800987594603896
 -- [34mElasticNetRegressor @012[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.02765108322778513, insample: 0.06180104261606859
 -- [34mElasticNetRegressor @994[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651162275441423, insample: 0.061801053881855784
 -- [34mElasticNetRegressor @306[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651155706182137, insample: 0.06180105710588575
 -- [34mElasticNetRegressor @576[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651162860262833, insample: 0.06180104657865728
 -- [34mElasticNetRegressor @704[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.0276511455748371, insample: 0.061801044145696406
 -- [34mElasticNetRegressor @652[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.02765113464601516, insample: 0.061801044145696406
 -- [34mElasticNetRegressor @867[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651141667503418, insample: 0.06180103987617271
 -- [34mElasticNetRegressor @584[39m


┌ Warning: Proximal GD did not converge in 1000 iterations.
└ @ MLJLinearModels C:\Users\Justin\.julia\packages\MLJLinearModels\KE4EE\src\fit\proxgrad.jl:64


outsample: 0.027651141667503418, insample: 0.06180103987617271
 -- [34mXGBoostRegressor @531[39m
outsample: 0.024815763345799297, insample: 0.4033048140864821
 -- [34mXGBoostRegressor @088[39m
outsample: 0.03659074980295988, insample: 0.34474251174858644
 -- [34mXGBoostRegressor @046[39m
outsample: 0.03897987810857149, insample: 0.3118486054318112
 -- [34mXGBoostRegressor @391[39m
outsample: 0.039683297779925394, insample: 0.20312468355680283
 -- [34mXGBoostRegressor @146[39m
outsample: 0.034509192497652864, insample: 0.11544644084833998
</code></pre></div></div>

<h2 id="gotcha-models-with-large-exposures-to-individual-features-tend-to-perform-poorly-or-inconsistently-out-of-sample">Gotcha: Models with large exposures to individual features tend to perform poorly or inconsistently out of sample</h2>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># MLJ matches the XGBoost implementation in Python, where num_round == n_estimators </span>

<span class="n">XGB</span> <span class="o">=</span> <span class="nd">@load</span> <span class="n">XGBoostRegressor</span> <span class="n">pkg</span><span class="o">=</span><span class="n">XGBoost</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span>
<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGB</span><span class="x">(</span><span class="n">eta</span> <span class="o">=</span> <span class="mf">0.01</span><span class="x">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">num_round</span><span class="o">=</span><span class="mi">1000</span><span class="x">);</span>
<span class="n">mach</span> <span class="o">=</span> <span class="n">machine</span><span class="x">(</span><span class="n">xgb</span><span class="x">,</span> <span class="n">df₁</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">],</span> <span class="n">df₁</span><span class="o">.</span><span class="n">target</span><span class="x">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="x">(</span><span class="n">mach</span><span class="x">,</span> <span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="x">)</span>

<span class="n">xgb_preds</span> <span class="o">=</span> <span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="x">(</span><span class="n">mach</span><span class="x">,</span> <span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">features</span><span class="x">]);</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xgb_preds</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>248653-element Vector{Float32}:
 0.5092171
 0.51353323
 0.5298325
 0.50988734
 0.50764424
 0.50148475
 0.504006
 0.49748185
 0.49696985
 0.48918203
 0.50696886
 0.51324135
 0.48414978
 ⋮
 0.48918062
 0.47421244
 0.5090075
 0.48367783
 0.47870287
 0.5039986
 0.4987926
 0.49181792
 0.51567954
 0.5039868
 0.48160774
 0.48305735
</code></pre></div></div>

<h3 id="our-predictions-have-correlation--02-in-either-direction-for-some-single-features">Our predictions have correlation &gt; 0.2 in either direction for some single features!</h3>
<p>Sure hope those features continue to act as they have in the past!</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cor_list</span> <span class="o">=</span> <span class="x">[]</span>
<span class="k">for</span> <span class="n">feature</span> <span class="k">in</span> <span class="n">features</span>
    <span class="n">append!</span><span class="x">(</span><span class="n">cor_list</span><span class="x">,</span> <span class="n">cor</span><span class="x">(</span><span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">feature</span><span class="x">],</span> <span class="n">xgb_preds</span><span class="x">))</span>
<span class="k">end</span>
    
<span class="n">describe</span><span class="x">(</span><span class="n">DataFrame</span><span class="x">(</span><span class="n">cor_list</span> <span class="o">=</span> <span class="n">cor_list</span><span class="x">),</span> <span class="o">:</span><span class="n">all</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>1 rows × 13 columns (omitted printing of 5 columns)</p><table class="data-frame"><thead><tr><th></th><th>variable</th><th>mean</th><th>std</th><th>min</th><th>q25</th><th>median</th><th>q75</th><th>max</th></tr><tr><th></th><th title="Symbol">Symbol</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>cor_list</td><td>0.0484105</td><td>0.0816448</td><td>-0.229774</td><td>0.00417808</td><td>0.0457962</td><td>0.108646</td><td>0.232515</td></tr></tbody></table></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># treating as one function since Julia gets snippy about subsetting with [!, column] in groupbys</span>

<span class="k">function</span><span class="nf"> norm_neut</span><span class="x">(</span><span class="n">df</span><span class="x">,</span> <span class="n">columns</span><span class="x">,</span> <span class="n">feats</span><span class="x">,</span> <span class="n">proportion</span><span class="o">=</span><span class="mf">1.0</span><span class="x">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">quantile</span><span class="x">(</span><span class="n">Normal</span><span class="x">(</span><span class="mf">0.0</span><span class="x">,</span><span class="mf">1.0</span><span class="x">),(</span><span class="n">ordinalrank</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">columns</span><span class="x">])</span> <span class="o">.-</span> <span class="mf">0.5</span><span class="x">)</span> <span class="o">./</span> <span class="n">length</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">columns</span><span class="x">]))</span>
    <span class="n">exposures</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="x">(</span><span class="n">df</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">feats</span><span class="x">])</span>
    <span class="n">neutralized</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">-</span> <span class="n">proportion</span> <span class="o">*</span> <span class="n">exposures</span> <span class="o">*</span> <span class="x">(</span><span class="n">pinv</span><span class="x">(</span><span class="n">exposures</span><span class="x">)</span> <span class="o">*</span> <span class="n">scores</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">neutralized</span> <span class="o">/</span> <span class="n">std</span><span class="x">(</span><span class="n">neutralized</span><span class="x">)</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df₂</span><span class="o">.</span><span class="n">preds</span> <span class="o">=</span> <span class="n">xgb_preds</span>

<span class="n">df₂</span><span class="x">[</span><span class="o">:</span><span class="x">,</span> <span class="o">:</span><span class="n">preds_neutralized</span><span class="x">]</span> <span class="o">=</span> <span class="n">combine</span><span class="x">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">norm_neut</span><span class="x">(</span><span class="n">x</span><span class="x">,</span> <span class="o">:</span><span class="n">preds</span><span class="x">,</span> <span class="n">features</span><span class="x">,</span> <span class="mf">0.5</span><span class="x">),</span> <span class="n">groupby</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="o">:</span><span class="n">erano</span><span class="x">))</span><span class="o">.</span><span class="n">x1</span>

<span class="n">x_min</span> <span class="o">=</span> <span class="n">minimum</span><span class="x">(</span><span class="n">df₂</span><span class="o">.</span><span class="n">preds_neutralized</span><span class="x">)</span>
<span class="n">x_max</span> <span class="o">=</span> <span class="n">maximum</span><span class="x">(</span><span class="n">df₂</span><span class="o">.</span><span class="n">preds_neutralized</span><span class="x">)</span>
<span class="n">X_std</span> <span class="o">=</span> <span class="x">(</span><span class="n">df₂</span><span class="o">.</span><span class="n">preds_neutralized</span> <span class="o">.-</span> <span class="n">x_min</span><span class="x">)</span> <span class="o">/</span> <span class="x">(</span><span class="n">x_max</span> <span class="o">.-</span> <span class="n">x_min</span><span class="x">)</span>
<span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="o">:</span><span class="n">preds_neutralized</span><span class="x">]</span> <span class="o">=</span> <span class="n">X_scaled</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">*</span> <span class="x">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">0</span><span class="x">)</span> <span class="o">.+</span> <span class="mi">0</span><span class="x">;</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">describe</span><span class="x">(</span><span class="n">df₂</span><span class="o">.</span><span class="n">preds_neutralized</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Summary Stats:
Length:         248653
Missing Count:  0
Mean:           0.512301
Minimum:        0.000000
1st Quartile:   0.445243
Median:         0.510633
3rd Quartile:   0.577324
Maximum:        1.000000
Type:           Float64
</code></pre></div></div>

<h3 id="now-our-single-feature-exposures-are-much-smaller">Now our single feature exposures are much smaller</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cor_list2</span> <span class="o">=</span> <span class="x">[]</span>
<span class="k">for</span> <span class="n">feature</span> <span class="k">in</span> <span class="n">features</span>
    <span class="n">append!</span><span class="x">(</span><span class="n">cor_list2</span><span class="x">,</span> <span class="n">cor</span><span class="x">(</span><span class="n">df₂</span><span class="x">[</span><span class="o">!</span><span class="x">,</span> <span class="n">feature</span><span class="x">],</span> <span class="n">df₂</span><span class="o">.</span><span class="n">preds_neutralized</span><span class="x">))</span>
<span class="k">end</span>
    
<span class="n">describe</span><span class="x">(</span><span class="n">DataFrame</span><span class="x">(</span><span class="n">cor_list2</span> <span class="o">=</span> <span class="n">cor_list2</span><span class="x">),</span> <span class="o">:</span><span class="n">all</span><span class="x">)</span>
</code></pre></div></div>

<div class="data-frame"><p>1 rows × 13 columns (omitted printing of 5 columns)</p><table class="data-frame"><thead><tr><th></th><th>variable</th><th>mean</th><th>std</th><th>min</th><th>q25</th><th>median</th><th>q75</th><th>max</th></tr><tr><th></th><th title="Symbol">Symbol</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th><th title="Float64">Float64</th></tr></thead><tbody><tr><th>1</th><td>cor_list2</td><td>0.0361127</td><td>0.0531799</td><td>-0.146887</td><td>0.00775735</td><td>0.0337416</td><td>0.0753398</td><td>0.155376</td></tr></tbody></table></div>

<h3 id="our-overall-score-goes-down-but-the-scores-are-more-consistent-than-before-this-leads-to-a-higher-sharpe">Our overall score goes down, but the scores are more consistent than before. This leads to a higher sharpe</h3>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">unbalanced_scores_per_era</span> <span class="o">=</span> <span class="n">combine</span><span class="x">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">cor</span><span class="x">(</span><span class="n">x</span><span class="o">.</span><span class="n">preds</span><span class="x">,</span> <span class="n">x</span><span class="o">.</span><span class="n">target</span><span class="x">),</span> <span class="n">groupby</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="o">:</span><span class="n">era</span><span class="x">))</span>
<span class="n">balanced_scores_per_era</span> <span class="o">=</span> <span class="n">combine</span><span class="x">(</span><span class="n">x</span> <span class="o">-&gt;</span> <span class="n">cor</span><span class="x">(</span><span class="n">x</span><span class="o">.</span><span class="n">preds_neutralized</span><span class="x">,</span> <span class="n">x</span><span class="o">.</span><span class="n">target</span><span class="x">),</span> <span class="n">groupby</span><span class="x">(</span><span class="n">df₂</span><span class="x">,</span> <span class="o">:</span><span class="n">era</span><span class="x">));</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">println</span><span class="x">(</span><span class="s">"score for high feature exposure: "</span><span class="x">,</span> <span class="n">mean</span><span class="x">(</span><span class="n">unbalanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>
<span class="n">println</span><span class="x">(</span><span class="s">"score for balanced feature expo: "</span><span class="x">,</span> <span class="n">mean</span><span class="x">(</span><span class="n">balanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>

<span class="n">println</span><span class="x">(</span><span class="s">"std for high feature exposure: "</span><span class="x">,</span> <span class="n">std</span><span class="x">(</span><span class="n">unbalanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>
<span class="n">println</span><span class="x">(</span><span class="s">"std for balanced feature expo: "</span><span class="x">,</span> <span class="n">std</span><span class="x">(</span><span class="n">balanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>

<span class="n">println</span><span class="x">(</span><span class="s">"sharpe for high feature exposure: "</span><span class="x">,</span> <span class="n">mean</span><span class="x">(</span><span class="n">unbalanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">)</span><span class="o">/</span><span class="n">std</span><span class="x">(</span><span class="n">unbalanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>
<span class="n">println</span><span class="x">(</span><span class="s">"sharpe for balanced feature expo: "</span><span class="x">,</span> <span class="n">mean</span><span class="x">(</span><span class="n">balanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">)</span><span class="o">/</span><span class="n">std</span><span class="x">(</span><span class="n">balanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>score for high feature exposure: 0.0368068530006
score for balanced feature expo: 0.03288299396994343
std for high feature exposure: 0.03848940885417861
std for balanced feature expo: 0.031585501268560856
sharpe for high feature exposure: 0.9562852248535912
sharpe for balanced feature expo: 1.0410787433876838
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">describe</span><span class="x">(</span><span class="n">balanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Summary Stats:
Length:         56
Missing Count:  0
Mean:           0.032883
Minimum:        -0.065154
1st Quartile:   0.013038
Median:         0.030797
3rd Quartile:   0.061884
Maximum:        0.091098
Type:           Float64
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">describe</span><span class="x">(</span><span class="n">unbalanced_scores_per_era</span><span class="o">.</span><span class="n">x1</span><span class="x">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Summary Stats:
Length:         56
Missing Count:  0
Mean:           0.036807
Minimum:        -0.085174
1st Quartile:   0.014656
Median:         0.033550
3rd Quartile:   0.062175
Maximum:        0.112687
Type:           Float64
</code></pre></div></div>


  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="BrickFrog/brickfrog-fastpages"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/numerai/mlj/scikit-learn/datascience/julia/2021/07/14/analysis-and-tips-julia.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
        <ul class="contact-list">
          <li class="p-name">Justin</li>
          <li><a class="u-email" href="mailto:fp-contact@hirejust.in">fp-contact@hirejust.in</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <p></p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/brickfrog" title="brickfrog"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://stackoverflow.com/users/12568287" title="12568287"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#stackoverflow"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/justin-tm" title="justin-tm"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a href="https://dev.to/brickfrog" title="brickfrog"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#devto"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
